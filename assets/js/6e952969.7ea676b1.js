"use strict";(globalThis.webpackChunkai_robotics_book=globalThis.webpackChunkai_robotics_book||[]).push([[6738],{4701:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"resources/glossary","title":"Glossary","description":"Key terms and definitions for Physical AI and Humanoid Robotics","source":"@site/docs/resources/glossary.md","sourceDirName":"resources","slug":"/resources/glossary","permalink":"/ai-robotics-book/docs/resources/glossary","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Glossary","description":"Key terms and definitions for Physical AI and Humanoid Robotics"},"sidebar":"tutorialSidebar","previous":{"title":"References","permalink":"/ai-robotics-book/docs/resources/references"}}');var r=i(4848),o=i(8453);const t={sidebar_position:2,title:"Glossary",description:"Key terms and definitions for Physical AI and Humanoid Robotics"},a="Glossary",c={},l=[{value:"A",id:"a",level:2},{value:"B",id:"b",level:2},{value:"C",id:"c",level:2},{value:"D",id:"d",level:2},{value:"E",id:"e",level:2},{value:"F",id:"f",level:2},{value:"G",id:"g",level:2},{value:"I",id:"i",level:2},{value:"J",id:"j",level:2},{value:"L",id:"l",level:2},{value:"M",id:"m",level:2},{value:"N",id:"n",level:2},{value:"O",id:"o",level:2},{value:"P",id:"p",level:2},{value:"Q",id:"q",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2},{value:"W",id:"w",level:2},{value:"X",id:"x",level:2},{value:"Z",id:"z",level:2}];function d(n){const e={h1:"h1",h2:"h2",header:"header",hr:"hr",p:"p",strong:"strong",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"glossary",children:"Glossary"})}),"\n",(0,r.jsx)(e.h2,{id:"a",children:"A"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Action (ROS 2)"}),"\n: A communication pattern for long-running tasks that provides goal, feedback, and result messages. Unlike services, actions can be preempted and report progress."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Actuator"}),"\n: A device that converts energy into motion. In humanoid robots, actuators (typically electric motors) drive the joints."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Articulation"}),"\n: A connected chain of rigid bodies (links) connected by joints. Humanoid robots are complex articulations with many degrees of freedom."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ASR (Automatic Speech Recognition)"}),"\n: Technology that converts spoken language into text. Used in voice interfaces for robot command input."]}),"\n",(0,r.jsx)(e.h2,{id:"b",children:"B"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Behavior Tree"}),"\n: A hierarchical structure for organizing robot behaviors. Used in Nav2 for composing navigation behaviors from primitive actions."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Bipedal Locomotion"}),"\n: Walking on two legs. Requires dynamic balance control and careful footstep planning."]}),"\n",(0,r.jsx)(e.h2,{id:"c",children:"C"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Callback"}),"\n: A function that is automatically called when an event occurs, such as receiving a message on a ROS 2 topic."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"CoM (Center of Mass)"}),"\n: The point where the total mass of a body can be considered concentrated. Critical for balance control in humanoid robots."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Costmap"}),"\n: A grid-based representation of the environment where each cell has a cost indicating traversability. Used for navigation planning."]}),"\n",(0,r.jsx)(e.h2,{id:"d",children:"D"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"DDS (Data Distribution Service)"}),"\n: The underlying middleware used by ROS 2 for communication. Provides discovery, QoS, and real-time capabilities."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Degrees of Freedom (DOF)"}),"\n: The number of independent parameters that define the configuration of a mechanical system. A humanoid robot may have 20-40+ DOF."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Digital Twin"}),"\n: A virtual representation of a physical robot that mirrors its state in real-time. Used for monitoring, testing, and predictive maintenance."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Domain Randomization"}),"\n: A technique for improving sim-to-real transfer by randomly varying simulation parameters during training."]}),"\n",(0,r.jsx)(e.h2,{id:"e",children:"E"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Embodied AI"}),"\n: Artificial intelligence systems that have physical form and interact with the real world through sensors and actuators."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"End Effector"}),"\n: The device at the end of a robotic arm, such as a gripper or hand. Used for manipulation tasks."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Executor (ROS 2)"}),"\n: A component that schedules and runs callbacks for nodes. Can be single-threaded or multi-threaded."]}),"\n",(0,r.jsx)(e.h2,{id:"f",children:"F"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Forward Kinematics"}),"\n: Computing the position and orientation of the end effector given joint angles."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Footstep Planning"}),"\n: Planning a sequence of foot placements for bipedal locomotion."]}),"\n",(0,r.jsx)(e.h2,{id:"g",children:"G"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Gazebo"}),"\n: An open-source robotics simulator that provides physics, sensor simulation, and ROS integration."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Grounding"}),"\n: The process of connecting abstract language concepts to concrete robot-executable actions and perceptions."]}),"\n",(0,r.jsx)(e.h2,{id:"i",children:"I"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"IMU (Inertial Measurement Unit)"}),"\n: A sensor combining accelerometers and gyroscopes to measure linear acceleration and angular velocity."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Intent Classification"}),"\n: Determining the user's intended action from natural language input."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Inverse Kinematics (IK)"}),"\n: Computing joint angles required to achieve a desired end effector position and orientation."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Isaac Sim"}),"\n: NVIDIA's robotics simulation platform built on Omniverse, providing photorealistic rendering and GPU-accelerated physics."]}),"\n",(0,r.jsx)(e.h2,{id:"j",children:"J"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Joint"}),"\n: A connection between two links that allows relative motion. Types include revolute (rotation) and prismatic (translation)."]}),"\n",(0,r.jsx)(e.h2,{id:"l",children:"L"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Launch File"}),"\n: A file that specifies how to start multiple ROS 2 nodes with configured parameters."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"LLM (Large Language Model)"}),"\n: A neural network trained on large text corpora that can understand and generate natural language."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Lifecycle Node"}),"\n: A ROS 2 node with managed state transitions (unconfigured, inactive, active, finalized) for deterministic startup/shutdown."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Link"}),"\n: A rigid body segment in a robot's kinematic chain, connected to other links via joints."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Localization"}),"\n: Determining the robot's position and orientation within a known map."]}),"\n",(0,r.jsx)(e.h2,{id:"m",children:"M"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"MCP (Model Context Protocol)"}),"\n: A protocol for integrating AI models with external tools and data sources."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Mermaid"}),"\n: A JavaScript-based diagramming tool that renders diagrams from text descriptions in Markdown."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Multi-Modal Perception"}),"\n: Combining information from multiple sensor types (vision, depth, proprioception) for robust understanding."]}),"\n",(0,r.jsx)(e.h2,{id:"n",children:"N"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Nav2"}),"\n: The ROS 2 Navigation Stack, providing autonomous navigation capabilities including path planning and obstacle avoidance."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Node (ROS 2)"}),"\n: A process that performs computation in ROS 2. Nodes communicate via topics, services, and actions."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"NLU (Natural Language Understanding)"}),"\n: Processing natural language to extract meaning, intent, and parameters."]}),"\n",(0,r.jsx)(e.h2,{id:"o",children:"O"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Odometry"}),"\n: Estimating robot pose change over time using sensor data (wheel encoders, IMU, visual)."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Omniverse"}),"\n: NVIDIA's platform for building and operating metaverse applications, underlying Isaac Sim."]}),"\n",(0,r.jsx)(e.h2,{id:"p",children:"P"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"PhysX"}),"\n: NVIDIA's physics simulation engine used in Isaac Sim for accurate dynamics and contact simulation."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Proprioception"}),"\n: The robot's sense of its own body state, including joint positions, velocities, and forces."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Publisher/Subscriber"}),"\n: A communication pattern where publishers send messages to topics and subscribers receive them. Supports one-to-many communication."]}),"\n",(0,r.jsx)(e.h2,{id:"q",children:"Q"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"QoS (Quality of Service)"}),"\n: ROS 2 settings that control reliability, durability, and deadline of communication."]}),"\n",(0,r.jsx)(e.h2,{id:"r",children:"R"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"rclpy"}),"\n: The ROS 2 Client Library for Python."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ROS 2"}),"\n: Robot Operating System 2, a middleware framework for robot software development."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"RTX"}),"\n: NVIDIA's ray tracing technology that enables photorealistic rendering in Isaac Sim."]}),"\n",(0,r.jsx)(e.h2,{id:"s",children:"S"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"SDF (Simulation Description Format)"}),"\n: An XML format for describing simulation worlds, models, and sensors in Gazebo."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Service (ROS 2)"}),"\n: A request-response communication pattern for synchronous operations."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Sim-to-Real Transfer"}),"\n: Transferring policies or models trained in simulation to work on real robots."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"SLAM (Simultaneous Localization and Mapping)"}),"\n: Building a map of an unknown environment while simultaneously tracking the robot's position within it."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Slot Filling"}),'\n: Extracting specific parameters from natural language commands (e.g., extracting "kitchen" from "go to the kitchen").']}),"\n",(0,r.jsx)(e.h2,{id:"t",children:"T"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"TF (Transform)"}),"\n: ROS 2's system for tracking coordinate frames over time, enabling transformation between different reference frames."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Topic (ROS 2)"}),"\n: A named bus for publish-subscribe communication in ROS 2."]}),"\n",(0,r.jsx)(e.h2,{id:"u",children:"U"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"URDF (Unified Robot Description Format)"}),"\n: An XML format for describing robot kinematics, dynamics, visual appearance, and collision geometry."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"USD (Universal Scene Description)"}),"\n: A file format for describing 3D scenes, used by Omniverse and Isaac Sim."]}),"\n",(0,r.jsx)(e.h2,{id:"v",children:"V"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"VLA (Vision-Language-Action)"}),"\n: Models that directly map visual observations and language commands to robot actions."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"VLM (Vision-Language Model)"}),"\n: Models that process both visual and textual inputs to understand scenes and answer questions."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"VSLAM (Visual SLAM)"}),"\n: SLAM using camera sensors as the primary input."]}),"\n",(0,r.jsx)(e.h2,{id:"w",children:"W"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Whole-Body Control"}),"\n: Controlling all joints of a humanoid robot simultaneously to achieve tasks while maintaining balance."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Workspace (ROS 2)"}),"\n: A directory containing ROS 2 packages with their source code, build artifacts, and installed files."]}),"\n",(0,r.jsx)(e.h2,{id:"x",children:"X"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Xacro"}),"\n: An XML macro language for creating modular and parameterized URDF descriptions."]}),"\n",(0,r.jsx)(e.h2,{id:"z",children:"Z"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ZMP (Zero Moment Point)"}),"\n: A point on the ground where the sum of horizontal inertial and gravity forces produces zero moment. Critical for bipedal balance."]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.p,{children:"This glossary covers key terms used throughout the Physical AI & Humanoid Robotics curriculum. Terms are cross-referenced where relevant."})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>t,x:()=>a});var s=i(6540);const r={},o=s.createContext(r);function t(n){const e=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:t(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);