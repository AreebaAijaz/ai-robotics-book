"use strict";(globalThis.webpackChunkai_robotics_book=globalThis.webpackChunkai_robotics_book||[]).push([[5024],{2141:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"module-2-simulation/sensor-simulation","title":"Sensor Simulation","description":"Simulating cameras, LiDAR, IMU, and force sensors for humanoid robots","source":"@site/docs/module-2-simulation/03-sensor-simulation.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/sensor-simulation","permalink":"/ai-robotics-book/docs/module-2-simulation/sensor-simulation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Sensor Simulation","description":"Simulating cameras, LiDAR, IMU, and force sensors for humanoid robots"},"sidebar":"tutorialSidebar","previous":{"title":"Unity Integration","permalink":"/ai-robotics-book/docs/module-2-simulation/unity-integration"},"next":{"title":"Digital Twins","permalink":"/ai-robotics-book/docs/module-2-simulation/digital-twins"}}');var i=a(4848),r=a(8453);const o={sidebar_position:3,title:"Sensor Simulation",description:"Simulating cameras, LiDAR, IMU, and force sensors for humanoid robots"},t="Sensor Simulation",l={},d=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Sensor Types for Humanoid Robots",id:"sensor-types-for-humanoid-robots",level:2},{value:"Camera Simulation",id:"camera-simulation",level:2},{value:"Gazebo Camera Configuration",id:"gazebo-camera-configuration",level:3},{value:"Depth Camera (RGB-D)",id:"depth-camera-rgb-d",level:3},{value:"Camera Noise Models in Python",id:"camera-noise-models-in-python",level:3},{value:"LiDAR Simulation",id:"lidar-simulation",level:2},{value:"2D LiDAR Configuration",id:"2d-lidar-configuration",level:3},{value:"3D LiDAR (Velodyne-style)",id:"3d-lidar-velodyne-style",level:3},{value:"IMU Simulation",id:"imu-simulation",level:2},{value:"IMU Configuration",id:"imu-configuration",level:3},{value:"IMU Noise Model",id:"imu-noise-model",level:3},{value:"Force/Torque Sensors",id:"forcetorque-sensors",level:2},{value:"Contact Sensors",id:"contact-sensors",level:3},{value:"Force/Torque Sensor",id:"forcetorque-sensor",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Camera Calibration",id:"exercise-1-camera-calibration",level:3},{value:"Exercise 2: IMU Allan Variance",id:"exercise-2-imu-allan-variance",level:3},{value:"Exercise 3: Contact Detection",id:"exercise-3-contact-detection",level:3},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Summary",id:"summary",level:2}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"sensor-simulation",children:"Sensor Simulation"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configure"})," camera sensors with realistic noise models"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Simulate"})," LiDAR and depth sensors for perception"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Model"})," IMU sensors with appropriate noise characteristics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Implement"})," force/torque sensors for contact detection"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Calibrate"})," simulated sensors to match real hardware"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Completed Chapters 1-2 of Module 2"}),"\n",(0,i.jsx)(n.li,{children:"Understanding of sensor noise models"}),"\n",(0,i.jsx)(n.li,{children:"Basic signal processing knowledge"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"sensor-types-for-humanoid-robots",children:"Sensor Types for Humanoid Robots"}),"\n",(0,i.jsx)(n.p,{children:"Humanoid robots rely on multiple sensor modalities:"}),"\n",(0,i.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Proprioceptive"\n        IMU[IMU]\n        ENC[Joint Encoders]\n        FT[Force/Torque]\n    end\n\n    subgraph "Exteroceptive"\n        CAM[Cameras]\n        LID[LiDAR]\n        DEP[Depth Sensors]\n    end\n\n    subgraph "Fusion"\n        SE[State Estimation]\n        SLAM[Visual SLAM]\n        OBJ[Object Detection]\n    end\n\n    IMU --\x3e SE\n    ENC --\x3e SE\n    FT --\x3e SE\n    CAM --\x3e SLAM\n    CAM --\x3e OBJ\n    LID --\x3e SLAM\n    DEP --\x3e OBJ\n\n    style SE fill:#e3f2fd\n    style SLAM fill:#c8e6c9\n    style OBJ fill:#ffe0b2'}),"\n",(0,i.jsx)(n.h2,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"gazebo-camera-configuration",children:"Gazebo Camera Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="head_camera_link">\n  <sensor name="head_camera" type="camera">\n    <always_on>true</always_on>\n    <update_rate>30</update_rate>\n    <visualize>true</visualize>\n\n    <camera name="head_camera">\n      <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\n      <image>\n        <width>1280</width>\n        <height>720</height>\n        <format>R8G8B8</format>\n      </image>\n      <clip>\n        <near>0.1</near>\n        <far>100</far>\n      </clip>\n\n      \x3c!-- Noise model --\x3e\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.007</stddev>\n      </noise>\n\n      \x3c!-- Lens distortion --\x3e\n      <distortion>\n        <k1>-0.25</k1>\n        <k2>0.12</k2>\n        <k3>0.0</k3>\n        <p1>-0.00028</p1>\n        <p2>-0.00005</p2>\n        <center>0.5 0.5</center>\n      </distortion>\n    </camera>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"depth-camera-rgb-d",children:"Depth Camera (RGB-D)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="depth_camera_link">\n  <sensor name="depth_camera" type="depth_camera">\n    <always_on>true</always_on>\n    <update_rate>30</update_rate>\n\n    <camera name="depth_camera">\n      <horizontal_fov>1.22</horizontal_fov>  \x3c!-- 70 degrees --\x3e\n      <image>\n        <width>640</width>\n        <height>480</height>\n        <format>R_FLOAT32</format>\n      </image>\n      <clip>\n        <near>0.3</near>\n        <far>10.0</far>\n      </clip>\n\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.01</stddev>  \x3c!-- 1cm depth noise --\x3e\n      </noise>\n    </camera>\n\n    <plugin filename="libgazebo_ros_depth_camera.so" name="depth_camera_plugin">\n      <ros>\n        <namespace>/humanoid</namespace>\n        <remapping>~/depth/image_raw:=depth/image</remapping>\n        <remapping>~/depth/camera_info:=depth/camera_info</remapping>\n        <remapping>~/points:=depth/points</remapping>\n      </ros>\n      <camera_name>depth_camera</camera_name>\n      <frame_name>depth_camera_optical_frame</frame_name>\n      <min_depth>0.3</min_depth>\n      <max_depth>10.0</max_depth>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"camera-noise-models-in-python",children:"Camera Noise Models in Python"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""Realistic camera noise simulation."""\n\nimport numpy as np\nimport cv2\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass CameraNoiseParams:\n    """Parameters for camera noise simulation."""\n    gaussian_sigma: float = 5.0      # Gaussian noise std dev\n    salt_pepper_prob: float = 0.001  # Salt and pepper probability\n    motion_blur_kernel: int = 0      # Motion blur kernel size (0 = disabled)\n    exposure_variation: float = 0.1  # Random exposure variation\n\n\nclass CameraNoiseSimulator:\n    """Simulate realistic camera noise."""\n\n    def __init__(self, params: CameraNoiseParams):\n        self.params = params\n\n    def add_gaussian_noise(self, image: np.ndarray) -> np.ndarray:\n        """Add Gaussian noise to image."""\n        noise = np.random.normal(0, self.params.gaussian_sigma, image.shape)\n        noisy = image.astype(np.float32) + noise\n        return np.clip(noisy, 0, 255).astype(np.uint8)\n\n    def add_salt_pepper(self, image: np.ndarray) -> np.ndarray:\n        """Add salt and pepper noise."""\n        noisy = image.copy()\n        # Salt\n        salt_mask = np.random.random(image.shape[:2]) < self.params.salt_pepper_prob / 2\n        noisy[salt_mask] = 255\n        # Pepper\n        pepper_mask = np.random.random(image.shape[:2]) < self.params.salt_pepper_prob / 2\n        noisy[pepper_mask] = 0\n        return noisy\n\n    def add_motion_blur(self, image: np.ndarray) -> np.ndarray:\n        """Add motion blur effect."""\n        if self.params.motion_blur_kernel == 0:\n            return image\n\n        kernel_size = self.params.motion_blur_kernel\n        kernel = np.zeros((kernel_size, kernel_size))\n        kernel[int((kernel_size-1)/2), :] = np.ones(kernel_size) / kernel_size\n        return cv2.filter2D(image, -1, kernel)\n\n    def vary_exposure(self, image: np.ndarray) -> np.ndarray:\n        """Simulate exposure variation."""\n        factor = 1.0 + np.random.uniform(\n            -self.params.exposure_variation,\n            self.params.exposure_variation\n        )\n        adjusted = image.astype(np.float32) * factor\n        return np.clip(adjusted, 0, 255).astype(np.uint8)\n\n    def apply_all(self, image: np.ndarray) -> np.ndarray:\n        """Apply all noise effects."""\n        result = self.vary_exposure(image)\n        result = self.add_gaussian_noise(result)\n        result = self.add_salt_pepper(result)\n        result = self.add_motion_blur(result)\n        return result\n'})}),"\n",(0,i.jsx)(n.h2,{id:"lidar-simulation",children:"LiDAR Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"2d-lidar-configuration",children:"2D LiDAR Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="lidar_link">\n  <sensor name="lidar" type="ray">\n    <always_on>true</always_on>\n    <update_rate>20</update_rate>\n    <visualize>true</visualize>\n\n    <ray>\n      <scan>\n        <horizontal>\n          <samples>720</samples>\n          <resolution>1</resolution>\n          <min_angle>-2.35619</min_angle>  \x3c!-- -135 degrees --\x3e\n          <max_angle>2.35619</max_angle>   \x3c!-- 135 degrees --\x3e\n        </horizontal>\n      </scan>\n      <range>\n        <min>0.1</min>\n        <max>30.0</max>\n        <resolution>0.01</resolution>\n      </range>\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.01</stddev>\n      </noise>\n    </ray>\n\n    <plugin filename="libgazebo_ros_ray_sensor.so" name="lidar_plugin">\n      <ros>\n        <namespace>/humanoid</namespace>\n        <remapping>~/out:=scan</remapping>\n      </ros>\n      <output_type>sensor_msgs/LaserScan</output_type>\n      <frame_name>lidar_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"3d-lidar-velodyne-style",children:"3D LiDAR (Velodyne-style)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="velodyne_link">\n  <sensor name="velodyne" type="gpu_lidar">\n    <always_on>true</always_on>\n    <update_rate>10</update_rate>\n    <visualize>true</visualize>\n\n    <lidar>\n      <scan>\n        <horizontal>\n          <samples>1800</samples>\n          <resolution>1</resolution>\n          <min_angle>-3.14159</min_angle>\n          <max_angle>3.14159</max_angle>\n        </horizontal>\n        <vertical>\n          <samples>16</samples>\n          <resolution>1</resolution>\n          <min_angle>-0.261799</min_angle>  \x3c!-- -15 degrees --\x3e\n          <max_angle>0.261799</max_angle>   \x3c!-- 15 degrees --\x3e\n        </vertical>\n      </scan>\n      <range>\n        <min>0.5</min>\n        <max>100.0</max>\n        <resolution>0.01</resolution>\n      </range>\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.02</stddev>\n      </noise>\n    </lidar>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,i.jsx)(n.h3,{id:"imu-configuration",children:"IMU Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="imu_link">\n  <sensor name="imu_sensor" type="imu">\n    <always_on>true</always_on>\n    <update_rate>1000</update_rate>\n\n    <imu>\n      \x3c!-- Angular velocity (gyroscope) --\x3e\n      <angular_velocity>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.0002</stddev>  \x3c!-- rad/s --\x3e\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.0002</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.0002</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </z>\n      </angular_velocity>\n\n      \x3c!-- Linear acceleration (accelerometer) --\x3e\n      <linear_acceleration>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.017</stddev>  \x3c!-- m/s^2 --\x3e\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.017</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>0.017</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </z>\n      </linear_acceleration>\n    </imu>\n\n    <plugin filename="libgazebo_ros_imu_sensor.so" name="imu_plugin">\n      <ros>\n        <namespace>/humanoid</namespace>\n        <remapping>~/out:=imu/data</remapping>\n      </ros>\n      <frame_name>imu_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"imu-noise-model",children:"IMU Noise Model"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""IMU noise simulation with bias drift."""\n\nimport numpy as np\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass IMUNoiseParams:\n    """IMU noise parameters (typical MEMS IMU)."""\n    # Gyroscope\n    gyro_noise_density: float = 0.0002      # rad/s/sqrt(Hz)\n    gyro_random_walk: float = 0.0000022     # rad/s^2/sqrt(Hz)\n    gyro_bias_init: float = 0.0001          # rad/s\n\n    # Accelerometer\n    accel_noise_density: float = 0.002      # m/s^2/sqrt(Hz)\n    accel_random_walk: float = 0.00002      # m/s^3/sqrt(Hz)\n    accel_bias_init: float = 0.01           # m/s^2\n\n\nclass IMUSimulator:\n    """Simulate IMU with realistic noise characteristics."""\n\n    def __init__(self, params: IMUNoiseParams, dt: float = 0.001):\n        self.params = params\n        self.dt = dt\n        self.sqrt_dt = np.sqrt(dt)\n\n        # Initialize biases\n        self.gyro_bias = np.random.normal(0, params.gyro_bias_init, 3)\n        self.accel_bias = np.random.normal(0, params.accel_bias_init, 3)\n\n    def update_biases(self):\n        """Update bias random walk."""\n        self.gyro_bias += np.random.normal(\n            0, self.params.gyro_random_walk * self.sqrt_dt, 3\n        )\n        self.accel_bias += np.random.normal(\n            0, self.params.accel_random_walk * self.sqrt_dt, 3\n        )\n\n    def add_noise(self, true_gyro: np.ndarray, true_accel: np.ndarray):\n        """Add noise to true IMU readings."""\n        self.update_biases()\n\n        # Gyroscope noise\n        gyro_noise = np.random.normal(\n            0, self.params.gyro_noise_density / self.sqrt_dt, 3\n        )\n        noisy_gyro = true_gyro + self.gyro_bias + gyro_noise\n\n        # Accelerometer noise\n        accel_noise = np.random.normal(\n            0, self.params.accel_noise_density / self.sqrt_dt, 3\n        )\n        noisy_accel = true_accel + self.accel_bias + accel_noise\n\n        return noisy_gyro, noisy_accel\n'})}),"\n",(0,i.jsx)(n.h2,{id:"forcetorque-sensors",children:"Force/Torque Sensors"}),"\n",(0,i.jsx)(n.h3,{id:"contact-sensors",children:"Contact Sensors"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Foot contact sensor --\x3e\n<gazebo reference="left_foot">\n  <sensor name="left_foot_contact" type="contact">\n    <always_on>true</always_on>\n    <update_rate>1000</update_rate>\n\n    <contact>\n      <collision>left_foot_collision</collision>\n    </contact>\n\n    <plugin filename="libgazebo_ros_ft_sensor.so" name="ft_sensor">\n      <ros>\n        <namespace>/humanoid</namespace>\n        <remapping>~/wrench:=left_foot/wrench</remapping>\n      </ros>\n      <body_name>left_foot</body_name>\n      <frame_name>left_foot</frame_name>\n      <update_rate>1000</update_rate>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"forcetorque-sensor",children:"Force/Torque Sensor"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'\x3c!-- 6-axis F/T sensor at wrist --\x3e\n<gazebo reference="left_wrist_ft_link">\n  <sensor name="left_wrist_ft" type="force_torque">\n    <always_on>true</always_on>\n    <update_rate>1000</update_rate>\n\n    <force_torque>\n      <frame>parent</frame>\n      <measure_direction>child_to_parent</measure_direction>\n    </force_torque>\n\n    <plugin filename="libgazebo_ros_ft_sensor.so" name="ft_sensor">\n      <ros>\n        <namespace>/humanoid</namespace>\n        <remapping>~/wrench:=left_wrist/wrench</remapping>\n      </ros>\n      <joint_name>left_wrist_ft_joint</joint_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsx)(n.h3,{id:"exercise-1-camera-calibration",children:"Exercise 1: Camera Calibration"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Create a checkerboard pattern in simulation"}),"\n",(0,i.jsx)(n.li,{children:"Capture images from multiple viewpoints"}),"\n",(0,i.jsx)(n.li,{children:"Use OpenCV to calibrate the camera and compare with ground truth"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-2-imu-allan-variance",children:"Exercise 2: IMU Allan Variance"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Record static IMU data for 1 hour (simulated)"}),"\n",(0,i.jsx)(n.li,{children:"Compute Allan variance plots"}),"\n",(0,i.jsx)(n.li,{children:"Extract noise parameters and compare with configuration"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-3-contact-detection",children:"Exercise 3: Contact Detection"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Add contact sensors to both feet"}),"\n",(0,i.jsx)(n.li,{children:"Implement a gait phase detector based on contact states"}),"\n",(0,i.jsx)(n.li,{children:"Visualize contact forces during a walking motion"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Why is bias modeling important for IMU simulation?"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"How do you choose appropriate noise parameters for sensor simulation?"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"What is the difference between contact sensors and force/torque sensors?"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"How does sensor update rate affect the fidelity of simulation?"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"This chapter covered sensor simulation for humanoid robots:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cameras"})," require noise, distortion, and exposure modeling"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LiDAR"})," sensors need appropriate range and angular resolution"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"IMU"})," simulation must include bias drift for realistic state estimation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Force/torque"})," sensors are critical for balance and manipulation"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Next, we'll explore digital twin concepts that bring all these elements together."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Next"}),": ",(0,i.jsx)(n.a,{href:"./digital-twins",children:"Digital Twins"})]})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>t});var s=a(6540);const i={},r=s.createContext(i);function o(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);